<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Opencv JS</title>
    <script async src="js/opencv.js" onload="openCvReady();"></script>
    <script src="js/utils.js"></script>
    <link rel="stylesheet" href="./style/style.css">
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.141.0/build/three.module.js",
                "GLTFLoader" : "https://unpkg.com/three@0.141.0/examples/jsm/loaders/GLTFLoader.js"
            }
        }
    </script>
</head>
<body>
    <div id="wrap">
        <video id="background"></video>
        <canvas id="canvas"></canvas>
        <video id="camInput" height="160" width="240"></video>
        <canvas id="canvasOutput" 
            data-coordinate_x="0" data-coordinate_y="0"
            data-coordinate_width="80" data-coordinate_height="80"
        >
        </canvas>
    </div>
    <script src="./js/main.js"></script>
</body>
<script type="module" src="./js/three.js"></script>
<script type="text/JavaScript">
    function openCvReady() {
        cv['onRuntimeInitialized'] = () => {
        let video = document.getElementById("camInput"); // video is the id of video tag
        navigator.mediaDevices.getUserMedia({ video: true, audio: false })
        .then(function(stream) {
            video.srcObject = stream;
            video.play();
        })
        .catch(function(err) {
            console.log("An error occurred! " + err);
        });
        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
        let gray = new cv.Mat();
        let cap = new cv.VideoCapture(camInput);
        let faces = new cv.RectVector();
        let classifier = new cv.CascadeClassifier();
        let utils = new Utils('errorMessage');
        let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml
        utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
            classifier.load(faceCascadeFile); // in the callback, load the cascade from file 
        });
        const FPS = 60;
        const canvasOutput = document.querySelector("#canvasOutput");
        function processVideo() {
            let begin = Date.now();
            cap.read(src);
            src.copyTo(dst);
            cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
            try{
                classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                // console.log(faces.size());
            } catch(err){
                //console.log(err);
            }
            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                let point1 = new cv.Point(face.x, face.y);
                canvasOutput.setAttribute("data-coordinate_x", face.x);
                //canvasOutput.setAttribute("data-coordinate_width", face.width);
                canvasOutput.setAttribute("data-coordinate_y", face.y);
                //canvasOutput.setAttribute("data-coordinate_height", face.height);
                let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
            }
            cv.imshow("canvasOutput", dst);
            let delay = 1000/FPS - (Date.now() - begin);
            setTimeout(processVideo, delay);
        }
        setTimeout(processVideo, 0);
        };
    }
</script>

</html>